{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6W_1Qe8_sxn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Medha Trust\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Bidirectional,Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xd8lfuFrtUoo",
    "outputId": "c432e566-3be2-47f1-f51d-ad4a7995dd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6508, 10)\n"
     ]
    }
   ],
   "source": [
    "# data = reuters.load_data()\n",
    "# (X_train,y_train),(y_train,y_test) = data\n",
    "data = pd.read_csv('medium_data.csv')\n",
    "data['title']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwvxXJLAun61",
    "outputId": "f199b113-b82c-4600-f57a-d33509efe2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  8237\n"
     ]
    }
   ],
   "source": [
    "data ['title'] = data['title'].apply(lambda x: x.replace(u'\\xa0',u' ').replace('\\u200a',' '))\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['title'])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Total number of words: \", total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "et63tXriyZBB",
    "outputId": "eb00d981-9733-4425-f4e7-b8af07abf754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total input sequences: 48461\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for line in data['title']:\n",
    "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "  for i in range(1,len(token_list)):\n",
    "    n_gram_sequence = token_list[:i+1]\n",
    "    input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# input_sequences\n",
    "print(\"total input sequences:\",len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuoH1MHavRks",
    "outputId": "9f0e51d7-4573-48a6-d233-beee569938b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 40\n"
     ]
    }
   ],
   "source": [
    "# input_sequences = np.array(input_sequences)\n",
    "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
    "print(\"Max Sequence Length:\", max_sequence_length)\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))\n",
    "X,y = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes = total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNJTc6nd4DzE",
    "outputId": "9021e7f2-3b7e-45de-e4a1-b1290d4890de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Medha Trust\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Medha Trust\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 39, 100)           823700    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 300)               301200    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8237)              2479337   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3604237 (13.75 MB)\n",
      "Trainable params: 3604237 (13.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words,100,input_length= max_sequence_length-1 ))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words,activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer ='adam', loss ='categorical_crossentropy',metrics= ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "weXIfjBA40gE",
    "outputId": "b7a7ee4d-d422-44bd-eb48-76095ecf1009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Medha Trust\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Medha Trust\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1515/1515 [==============================] - 245s 153ms/step - loss: 6.9985 - accuracy: 0.0847\n",
      "Epoch 2/50\n",
      "1515/1515 [==============================] - 182s 120ms/step - loss: 6.1697 - accuracy: 0.1389\n",
      "Epoch 3/50\n",
      " 845/1515 [===============>..............] - ETA: 1:20 - loss: 5.6262 - accuracy: 0.1665"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,y,epochs =50,verbose=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKL-hQJmB3Ir",
    "outputId": "fbfd3629-f3f7-4efa-84c1-480b5de473e4"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyCE-Cm_CcgK",
    "outputId": "dfc7aa60-9ce9-4cca-c7e3-f8ac69fb6ba2"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "model_filename = 'model.h5'\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "0_t5tyyXBuy2",
    "outputId": "00e63e2e-69c6-40ba-b976-eaaa9bfa0f87"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history,metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel(metric)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "vQj9h5G2BufQ",
    "outputId": "a6c0b5d1-9e80-4f12-db92-8a15cc8aadb4"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjP1DD6h5YW_",
    "outputId": "198a10bf-ecd6-476d-a279-266c9b550f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed text: hypothesis\n",
      "Predicted next words: hypothesis testing glossary for\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(seed_text, model, tokenizer, max_sequence_length):\n",
    "    for _ in range(3):  # Predict the next 3 words\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_id = np.argmax(predicted_probs)\n",
    "        predicted_word = tokenizer.index_word[predicted_id]\n",
    "        seed_text += \" \" + predicted_word\n",
    "    return seed_text\n",
    "\n",
    "seed_text = \"hypothesis\"\n",
    "predicted_text = predict_next_word(seed_text, model, tokenizer, max_sequence_length)\n",
    "print(\"Seed text:\", seed_text)\n",
    "print(\"Predicted next words:\", predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UsBCy1y_Se6",
    "outputId": "80b419e9-24c7-446f-c922-bb7332e2862b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: generated_data.csv\n"
     ]
    }
   ],
   "source": [
    "# corpus = [\n",
    "#     \"I enjoy solving coding problems\",\n",
    "#     \"Machine learning opens new possibilities\",\n",
    "#     \"Programming languages shape our digital world\",\n",
    "#     \"Data analysis drives informed decisions\",\n",
    "#     \"I love exploring innovative solutions\",\n",
    "#     \"Artificial intelligence revolutionizes industries\",\n",
    "#     \"Python empowers developers with flexibility\",\n",
    "#     \"Learning new skills broadens horizons\",\n",
    "#     \"Coding challenges enhance problem-solving abilities\",\n",
    "#     \"Innovation in technology fuels progress\",\n",
    "#     \"I like building creative applications\",\n",
    "#     \"Programming is a journey of continuous learning\",\n",
    "#     \"Machine learning algorithms unlock insights\",\n",
    "#     \"Data analysis uncovers hidden patterns\",\n",
    "#     \"Artificial intelligence reshapes business landscapes\",\n",
    "#     \"I enjoy the art of coding\",\n",
    "#     \"Python simplifies complex tasks\",\n",
    "#     \"Learning and growing in the tech field\",\n",
    "#     \"Programming languages evolve with time\",\n",
    "#     \"Challenges in coding foster resilience\",\n",
    "#     \"Innovative solutions drive technological advancements\",\n",
    "#     \"Machine learning transforms raw data into knowledge\",\n",
    "#     \"Data analysis guides strategic decision-making\",\n",
    "#     \"Artificial intelligence enhances human capabilities\",\n",
    "#     \"I like creating software that makes a difference\",\n",
    "#     \"Exploring the depths of coding possibilities\",\n",
    "#     \"Python, a language of endless potential\",\n",
    "#     \"Learning from challenges accelerates personal growth\",\n",
    "#     \"Programming languages, a means of expression\",\n",
    "#     \"Machine learning, the science of prediction\",\n",
    "#     \"Data analysis, the key to actionable insights\",\n",
    "#     \"Artificial intelligence, a catalyst for change\",\n",
    "#     \"I enjoy the challenge of coding puzzles\",\n",
    "#     \"Python, a versatile and powerful language\",\n",
    "#     \"Learning coding principles for success\",\n",
    "#     \"Programming languages, the building blocks of software\",\n",
    "#     \"Machine learning algorithms, the heart of AI\",\n",
    "#     \"Data analysis, uncovering the story in data\",\n",
    "#     \"Artificial intelligence, pushing boundaries\",\n",
    "#     \"I like coding for fun and innovation\",\n",
    "#     \"Exploring the possibilities of machine learning\",\n",
    "#     \"Python, the language of automation\",\n",
    "#     \"Learning data structures for efficient coding\",\n",
    "#     \"Programming languages, tools for creation\",\n",
    "#     \"Machine learning models, predicting the future\",\n",
    "#     \"Data analysis techniques, revealing trends\",\n",
    "#     \"Artificial intelligence applications, endless possibilities\",\n",
    "#     \"I enjoy the process of debugging code\",\n",
    "#     \"Python scripting, simplifying tasks\",\n",
    "#     \"Learning algorithms for computational thinking\",\n",
    "#     \"Programming languages, a medium of communication\",\n",
    "#     \"Machine learning advancements, shaping industries\",\n",
    "#     \"Data analysis skills, a competitive edge\",\n",
    "#     \"Artificial intelligence systems, driving efficiency\",\n",
    "#     \"I like developing software with impact\",\n",
    "#     \"Exploring the nuances of coding languages\",\n",
    "#     \"Python, a language loved by developers\",\n",
    "#     \"Learning computer science fundamentals\",\n",
    "#     \"Programming languages, a canvas for creativity\",\n",
    "#     \"Machine learning applications, solving complex problems\",\n",
    "#     \"Data analysis insights, guiding decision-makers\",\n",
    "#     \"Artificial intelligence innovations, changing the game\",\n",
    "#     \"I enjoy the challenge of coding challenges\",\n",
    "#     \"Python, a language for web development\",\n",
    "#     \"Learning software engineering principles\",\n",
    "#     \"Programming languages, tools of the trade\",\n",
    "#     \"Machine learning algorithms, predicting outcomes\",\n",
    "#     \"Data analysis, unlocking the power of data\",\n",
    "#     \"Artificial intelligence, a driving force\",\n",
    "#     \"I like coding for innovation and progress\",\n",
    "#     \"Exploring the endless possibilities of programming\",\n",
    "#     \"Python, a language that empowers developers\",\n",
    "#     \"Learning coding best practices\",\n",
    "#     \"Programming languages, a foundation for technology\",\n",
    "#     \"Machine learning models, unlocking potential\",\n",
    "#     \"Data analysis, extracting meaningful insights\",\n",
    "#     \"Artificial intelligence, shaping the future landscape\",\n",
    "#     \"I enjoy the satisfaction of solving coding puzzles\",\n",
    "#     \"Python scripting, automating tasks seamlessly\",\n",
    "#     \"Learning algorithms, mastering the art of coding\",\n",
    "#     \"Programming languages, a gateway to creation\",\n",
    "#     \"Machine learning advancements, predicting trends\",\n",
    "#     \"Data analysis techniques, revealing valuable insights\",\n",
    "#     \"Artificial intelligence applications, transforming industries\",\n",
    "#     \"I like developing software that makes a positive impact\",\n",
    "#     \"Exploring the intricacies of coding languages\",\n",
    "#     \"Python, a language known for its simplicity\",\n",
    "#     \"Learning computer science principles for problem-solving\",\n",
    "#     \"Programming languages, a means of expressing ideas\",\n",
    "#     \"Machine learning applications, driving innovation\",\n",
    "#     \"Data analysis skills, enabling informed decision-making\",\n",
    "#     \"Artificial intelligence, a catalyst for technological change\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# import csv\n",
    "# csv_file_path = \"generated_data.csv\"\n",
    "# with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     csv_writer.writerow([\"Sentence\"])  # Write header\n",
    "\n",
    "#     for sentence in corpus:\n",
    "#         csv_writer.writerow([sentence])\n",
    "\n",
    "# print(f\"CSV file saved at: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bR7sHnDEf-S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

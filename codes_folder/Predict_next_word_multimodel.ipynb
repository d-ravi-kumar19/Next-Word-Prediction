{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFq1row8HyhH",
        "outputId": "ef54b1c5-59bf-43ab-8ede-3d7cd400ce5a",
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jan 31 06:07:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ic7CqmQIYzj",
        "outputId": "9b856fbe-2914-4ee3-b5bb-c0d98de63188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6W_1Qe8_sxn5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.layers import Embedding,LSTM,GRU,Bidirectional,Dense,Attention\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow_addons.seq2seq import BahdanauAttention\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd8lfuFrtUoo",
        "outputId": "3af0901a-985c-4729-c30e-c6a6842f9ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6508, 10)\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/Next-word-pred/medium_data.csv')\n",
        "data['title']\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwvxXJLAun61",
        "outputId": "bf1d42c4-b2a4-4ae8-ef02-fb698382d4b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of words:  8237\n"
          ]
        }
      ],
      "source": [
        "data ['title'] = data['title'].apply(lambda x: x.replace(u'\\xa0',u' ').replace('\\u200a',' '))\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['title'])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(\"Total number of words: \", total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et63tXriyZBB",
        "outputId": "ee0e41cf-fcf3-4e9e-92f4-302b4501ae80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total input sequences: 48461\n"
          ]
        }
      ],
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in data['title']:\n",
        "  # print(line)\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  # print(token_list)\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# input_sequences\n",
        "print(\"total input sequences:\",len(input_sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuoH1MHavRks",
        "outputId": "898f62b3-a527-4f69-ef7b-8f519cf9ed07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 40\n"
          ]
        }
      ],
      "source": [
        "# input_sequences = np.array(input_sequences)\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
        "print(\"Max Sequence Length:\", max_sequence_length)\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))\n",
        "X,y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes = total_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfcmQ7BACcsx"
      },
      "source": [
        "### Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNJTc6nd4DzE",
        "outputId": "e0b663ef-395b-47c1-a36d-a97f170d6705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 39, 100)           823700    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 300)               301200    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8237)              2479337   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3604237 (13.75 MB)\n",
            "Trainable params: 3604237 (13.75 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1515/1515 [==============================] - 30s 18ms/step - loss: 6.7324 - accuracy: 0.1310\n",
            "Epoch 2/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 6.5399 - accuracy: 0.1609\n",
            "Epoch 3/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 6.0314 - accuracy: 0.1749\n",
            "Epoch 4/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 4.8082 - accuracy: 0.2110\n",
            "Epoch 5/50\n",
            "1515/1515 [==============================] - 21s 14ms/step - loss: 4.2701 - accuracy: 0.2528\n",
            "Epoch 6/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 3.9174 - accuracy: 0.2867\n",
            "Epoch 7/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 3.7995 - accuracy: 0.3092\n",
            "Epoch 8/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 3.5444 - accuracy: 0.3331\n",
            "Epoch 9/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 3.4182 - accuracy: 0.3474\n",
            "Epoch 10/50\n",
            "1515/1515 [==============================] - 24s 16ms/step - loss: 3.3366 - accuracy: 0.3606\n",
            "Epoch 11/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 3.2527 - accuracy: 0.3737\n",
            "Epoch 12/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 3.1161 - accuracy: 0.3854\n",
            "Epoch 13/50\n",
            "1515/1515 [==============================] - 18s 12ms/step - loss: 3.0517 - accuracy: 0.3944\n",
            "Epoch 14/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.9776 - accuracy: 0.4067\n",
            "Epoch 15/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.9265 - accuracy: 0.4149\n",
            "Epoch 16/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.8818 - accuracy: 0.4182\n",
            "Epoch 17/50\n",
            "1515/1515 [==============================] - 18s 12ms/step - loss: 2.8944 - accuracy: 0.4224\n",
            "Epoch 18/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.8879 - accuracy: 0.4223\n",
            "Epoch 19/50\n",
            "1515/1515 [==============================] - 18s 12ms/step - loss: 2.8581 - accuracy: 0.4265\n",
            "Epoch 20/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.7650 - accuracy: 0.4373\n",
            "Epoch 21/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.7705 - accuracy: 0.4396\n",
            "Epoch 22/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.8607 - accuracy: 0.4259\n",
            "Epoch 23/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.7285 - accuracy: 0.4482\n",
            "Epoch 24/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.7334 - accuracy: 0.4489\n",
            "Epoch 25/50\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.6964 - accuracy: 0.4559\n",
            "Epoch 26/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.7744 - accuracy: 0.4489\n",
            "Epoch 27/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.7161 - accuracy: 0.4536\n",
            "Epoch 28/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.6758 - accuracy: 0.4597\n",
            "Epoch 29/50\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.6567 - accuracy: 0.4633\n",
            "Epoch 30/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.7077 - accuracy: 0.4625\n",
            "Epoch 31/50\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.6199 - accuracy: 0.4702\n",
            "Epoch 32/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.5886 - accuracy: 0.4749\n",
            "Epoch 33/50\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.5830 - accuracy: 0.4757\n",
            "Epoch 34/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5648 - accuracy: 0.4779\n",
            "Epoch 35/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5600 - accuracy: 0.4823\n",
            "Epoch 36/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5985 - accuracy: 0.4785\n",
            "Epoch 37/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5778 - accuracy: 0.4837\n",
            "Epoch 38/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.6133 - accuracy: 0.4792\n",
            "Epoch 39/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5528 - accuracy: 0.4835\n",
            "Epoch 40/50\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.5479 - accuracy: 0.4878\n",
            "Epoch 41/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5675 - accuracy: 0.4840\n",
            "Epoch 42/50\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.5447 - accuracy: 0.4873\n",
            "Epoch 43/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5250 - accuracy: 0.4914\n",
            "Epoch 44/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.5140 - accuracy: 0.4963\n",
            "Epoch 45/50\n",
            "1515/1515 [==============================] - 21s 14ms/step - loss: 2.5311 - accuracy: 0.4894\n",
            "Epoch 46/50\n",
            "1515/1515 [==============================] - 23s 15ms/step - loss: 2.5824 - accuracy: 0.4887\n",
            "Epoch 47/50\n",
            "1515/1515 [==============================] - 21s 14ms/step - loss: 2.6260 - accuracy: 0.4846\n",
            "Epoch 48/50\n",
            "1515/1515 [==============================] - 19s 13ms/step - loss: 2.5727 - accuracy: 0.4923\n",
            "Epoch 49/50\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.5267 - accuracy: 0.4944\n",
            "Epoch 50/50\n",
            "1515/1515 [==============================] - 24s 16ms/step - loss: 2.5010 - accuracy: 0.4991\n",
            "<keras.src.engine.sequential.Sequential object at 0x7eaf14147eb0>\n"
          ]
        }
      ],
      "source": [
        "model_bilstm = Sequential()\n",
        "model_bilstm.add(Embedding(total_words,100,input_length= max_sequence_length-1 ))\n",
        "model_bilstm.add(Bidirectional(LSTM(150)))\n",
        "model_bilstm.add(Dense(total_words,activation = 'softmax'))\n",
        "adam = Adam(learning_rate= 0.01)\n",
        "model_bilstm.compile(optimizer =adam, loss ='categorical_crossentropy',metrics= ['accuracy'])\n",
        "model_bilstm.summary()\n",
        "\n",
        "history_bilstm = model_bilstm.fit(X, y, epochs=50, verbose=1,batch_size=32)\n",
        "print(model_bilstm)\n",
        "\n",
        "# model_filename = 'model.h5'\n",
        "model_bilstm.save('bilstm_model.h5')\n",
        "# tokenizer.to_json(\"bilstm_tokenizer.json\")\n",
        "\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(tokenizer_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WI3cbP_rQOKN"
      },
      "outputs": [],
      "source": [
        "model_bilstm.save('/content/drive/MyDrive/ColabNotebooks/Next-word-pred/Models/bilstm_model.h5')\n",
        "# tokenizer.to_json(\"bilstm_tokenizer.json\")\n",
        "\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "with open('/content/drive/MyDrive/ColabNotebooks/Next-word-pred/Models/tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(tokenizer_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebkXbRQiYNEA",
        "outputId": "ae19c025-bdca-49a1-b186-0f24f29ad440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1515/1515 [==============================] - 14s 9ms/step - loss: 2.0925 - accuracy: 0.5615\n",
            "BiLSTM Model Evaluation: [2.0924787521362305, 0.5615030527114868]\n"
          ]
        }
      ],
      "source": [
        "evaluation_bilstm = model_bilstm.evaluate(X, y)\n",
        "print(\"BiLSTM Model Evaluation:\", evaluation_bilstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQX9vIRsMZQj",
        "outputId": "0f9cc1f6-4c5e-4fd9-e33f-5f0e64fbfeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1515/1515 [==============================] - 20s 13ms/step - loss: 2.5521 - accuracy: 0.4967\n",
            "Epoch 2/5\n",
            "1515/1515 [==============================] - 25s 16ms/step - loss: 2.5653 - accuracy: 0.4937\n",
            "Epoch 3/5\n",
            "1515/1515 [==============================] - 22s 14ms/step - loss: 2.5553 - accuracy: 0.4956\n",
            "Epoch 4/5\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.4951 - accuracy: 0.5031\n",
            "Epoch 5/5\n",
            "1515/1515 [==============================] - 19s 12ms/step - loss: 2.5230 - accuracy: 0.4995\n",
            "CPU times: user 1min 26s, sys: 8.38 s, total: 1min 34s\n",
            "Wall time: 2min 25s\n"
          ]
        }
      ],
      "source": [
        "%time history_bilstm = model_bilstm.fit(X, y, epochs=5, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhxJWGEW14p6",
        "outputId": "e6a7c188-0b5e-4caf-e60c-9267409f3aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1511/1515 [============================>.] - ETA: 0s - loss: 2.4794 - accuracy: 0.5029"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1515/1515 [==============================] - 19s 13ms/step - loss: 2.4810 - accuracy: 0.5027\n",
            "Epoch 2/5\n",
            "1515/1515 [==============================] - ETA: 0s - loss: 2.4927 - accuracy: 0.5064"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1515/1515 [==============================] - 20s 13ms/step - loss: 2.4927 - accuracy: 0.5064\n",
            "Epoch 3/5\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 2.4947 - accuracy: 0.5027"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1515/1515 [==============================] - 18s 12ms/step - loss: 2.4947 - accuracy: 0.5027\n",
            "Epoch 4/5\n",
            "1511/1515 [============================>.] - ETA: 0s - loss: 2.5287 - accuracy: 0.5029"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1515/1515 [==============================] - 19s 13ms/step - loss: 2.5290 - accuracy: 0.5027\n",
            "Epoch 5/5\n",
            "1515/1515 [==============================] - ETA: 0s - loss: 2.4756 - accuracy: 0.5062"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1515/1515 [==============================] - 18s 12ms/step - loss: 2.4756 - accuracy: 0.5062\n",
            "CPU times: user 1min 24s, sys: 9.37 s, total: 1min 33s\n",
            "Wall time: 1min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "logs_path = '/content/drive/MyDrive/ColabNotebooks/Next-word-pred/logs/'\n",
        "\n",
        "checkpoint_filepath = logs_path + 'model_bilstm_checkpoint.h5'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with the ModelCheckpoint callback\n",
        "history_bilstm_model = model_bilstm.fit(\n",
        "    X, y,\n",
        "    epochs=5,\n",
        "    callbacks=[model_checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P-FGQHC-SaVV"
      },
      "outputs": [],
      "source": [
        "models_path= '/content/drive/MyDrive/ColabNotebooks/Next-word-pred/Models/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky_GSQXCDdxg"
      },
      "source": [
        "### GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SILPXZ3OMcCz",
        "outputId": "c16291b1-46da-4c69-a80f-1dbcf816c648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 39, 100)           823700    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 150)               113400    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8237)              1243787   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2180887 (8.32 MB)\n",
            "Trainable params: 2180887 (8.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1515/1515 [==============================] - 26s 16ms/step - loss: 6.8154 - accuracy: 0.1293\n",
            "Epoch 2/50\n",
            "1515/1515 [==============================] - 17s 11ms/step - loss: 5.8190 - accuracy: 0.1727\n",
            "Epoch 3/50\n",
            "1515/1515 [==============================] - 16s 11ms/step - loss: 5.1187 - accuracy: 0.1954\n",
            "Epoch 4/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 4.4055 - accuracy: 0.2295\n",
            "Epoch 5/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 3.8412 - accuracy: 0.2810\n",
            "Epoch 6/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 3.4805 - accuracy: 0.3218\n",
            "Epoch 7/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 3.1157 - accuracy: 0.3759\n",
            "Epoch 8/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.9404 - accuracy: 0.4016\n",
            "Epoch 9/50\n",
            "1515/1515 [==============================] - 16s 11ms/step - loss: 2.8299 - accuracy: 0.4195\n",
            "Epoch 10/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.7372 - accuracy: 0.4335\n",
            "Epoch 11/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.6598 - accuracy: 0.4464\n",
            "Epoch 12/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.5762 - accuracy: 0.4566\n",
            "Epoch 13/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.5302 - accuracy: 0.4648\n",
            "Epoch 14/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.4593 - accuracy: 0.4801\n",
            "Epoch 15/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.4015 - accuracy: 0.4888\n",
            "Epoch 16/50\n",
            "1515/1515 [==============================] - 16s 11ms/step - loss: 2.3941 - accuracy: 0.4871\n",
            "Epoch 17/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.3785 - accuracy: 0.4931\n",
            "Epoch 18/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.3493 - accuracy: 0.5021\n",
            "Epoch 19/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.3811 - accuracy: 0.4960\n",
            "Epoch 20/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.3633 - accuracy: 0.5002\n",
            "Epoch 21/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.3634 - accuracy: 0.4988\n",
            "Epoch 22/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.3254 - accuracy: 0.5053\n",
            "Epoch 23/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2954 - accuracy: 0.5123\n",
            "Epoch 24/50\n",
            "1515/1515 [==============================] - 16s 11ms/step - loss: 2.3209 - accuracy: 0.5096\n",
            "Epoch 25/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.3513 - accuracy: 0.5052\n",
            "Epoch 26/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.3393 - accuracy: 0.5087\n",
            "Epoch 27/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.2875 - accuracy: 0.5157\n",
            "Epoch 28/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.2609 - accuracy: 0.5197\n",
            "Epoch 29/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2810 - accuracy: 0.5196\n",
            "Epoch 30/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2732 - accuracy: 0.5208\n",
            "Epoch 31/50\n",
            "1515/1515 [==============================] - 17s 11ms/step - loss: 2.2370 - accuracy: 0.5258\n",
            "Epoch 32/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2661 - accuracy: 0.5228\n",
            "Epoch 33/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2675 - accuracy: 0.5223\n",
            "Epoch 34/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2553 - accuracy: 0.5276\n",
            "Epoch 35/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2826 - accuracy: 0.5204\n",
            "Epoch 36/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2681 - accuracy: 0.5237\n",
            "Epoch 37/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.2318 - accuracy: 0.5291\n",
            "Epoch 38/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.2440 - accuracy: 0.5291\n",
            "Epoch 39/50\n",
            "1515/1515 [==============================] - 16s 10ms/step - loss: 2.2902 - accuracy: 0.5210\n",
            "Epoch 40/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2626 - accuracy: 0.5259\n",
            "Epoch 41/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2495 - accuracy: 0.5283\n",
            "Epoch 42/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2148 - accuracy: 0.5341\n",
            "Epoch 43/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2666 - accuracy: 0.5263\n",
            "Epoch 44/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2508 - accuracy: 0.5317\n",
            "Epoch 45/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2337 - accuracy: 0.5302\n",
            "Epoch 46/50\n",
            "1515/1515 [==============================] - 16s 11ms/step - loss: 2.2233 - accuracy: 0.5341\n",
            "Epoch 47/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2904 - accuracy: 0.5265\n",
            "Epoch 48/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2272 - accuracy: 0.5364\n",
            "Epoch 49/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2845 - accuracy: 0.5316\n",
            "Epoch 50/50\n",
            "1515/1515 [==============================] - 15s 10ms/step - loss: 2.2738 - accuracy: 0.5324\n",
            "<keras.src.engine.sequential.Sequential object at 0x7eaf0af8c5b0>\n"
          ]
        }
      ],
      "source": [
        "model_gru = Sequential()\n",
        "model_gru.add(Embedding(total_words,100,input_length= max_sequence_length-1 ))\n",
        "# gru_model.add(Bidirectional(LSTM(150)))\n",
        "model_gru.add(GRU(150))\n",
        "model_gru.add(Dense(total_words,activation = 'softmax'))\n",
        "adam = Adam(learning_rate= 0.01)\n",
        "model_gru.compile(optimizer =adam, loss ='categorical_crossentropy',metrics= ['accuracy'])\n",
        "model_gru.summary()\n",
        "\n",
        "\n",
        "history_gru = model_gru.fit(X, y, epochs=50, verbose=1,batch_size=32)\n",
        "\n",
        "print(model_gru)\n",
        "\n",
        "# model_filename = 'model.h5'\n",
        "model_gru.save(models_path + 'gru_model.h5')\n",
        "# tokenizer.to_json(\"gru_tokenizer.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LyliVGxGiyc"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "Ro8xmy26GmiG",
        "outputId": "2e0eecb0-1b28-49b5-e5d1-b33150cc8825"
      },
      "outputs": [],
      "source": [
        "# # Attention Model\n",
        "# model_attention = Sequential()\n",
        "# model_attention.add(Embedding(total_words, 100, input_length=max_sequence_length - 1))\n",
        "# model_attention.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "# model_attention.add(Attention(use_scale=True))\n",
        "# model_attention.add(Dense(total_words, activation='softmax'))\n",
        "# model_attention.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history_attention = model_attention.fit(X, y, epochs=50, verbose=1,batch_size=32)\n",
        "# model_attention.save(models_path + 'attention_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEZIAUIpGtAe"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsTChyD7Gmeg"
      },
      "outputs": [],
      "source": [
        "# # Transformer Model using GPT-2\n",
        "# tokenizer_gpt2 = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# model_gpt2 = TFGPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer_gpt2.eos_token_id)\n",
        "\n",
        "# # Save GPT-2 model (replace 'path_to_save' with your desired path)\n",
        "# model_gpt2.save_pretrained('path_to_save')\n",
        "\n",
        "# # Example usage for generating next words using GPT-2\n",
        "# inputs = tokenizer_gpt2.encode(\"your seed text\", return_tensors='tf')\n",
        "# outputs = model_gpt2.generate(inputs, max_length=50, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
        "# predicted_text = tokenizer_gpt2.decode(outputs[0], skip_special_tokens=True)\n",
        "# print(\"Predicted next words (GPT-2):\", predicted_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjP1DD6h5YW_",
        "outputId": "0376b05c-acf6-468d-e726-bdb7f9794a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed text: hypothesis\n",
            "Predicted next words: hypothesis testing glossary for\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word(seed_text, model, tokenizer, max_sequence_length):\n",
        "    for _ in range(3):  # Predict the next 3 words\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_id = np.argmax(predicted_probs)\n",
        "        predicted_word = tokenizer.index_word[predicted_id]\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n",
        "\n",
        "# seed_text = \"hypothesis\"\n",
        "# predicted_text = predict_next_word(seed_text, , tokenizer, max_sequence_length)\n",
        "# print(\"Seed text:\", seed_text)\n",
        "# print(\"Predicted next words:\", predicted_text)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
